# sign-language-recognition using hand gesture 
This project focuses on developing a real-time system for recognizing American Sign Language (ASL) gestures using deep learning. Designed to enhance communication for individuals with hearing and speech impairments, the system integrates: 

TensorFlow for training a Convolutional Neural Network (CNN).
A custom dataset of hand gestures collected and preprocessed for robust model training.
A user-friendly GUI to display predictions interactively.

Features:
Real-time hand gesture recognition with minimal latency.
Highly accurate CNN-based model trained on diverse datasets.
Scalable architecture compatible with various hardware.
